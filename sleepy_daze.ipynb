{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sleepy-daze",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTc9Z+Lv45acxKgG5ebgof",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afiaka87/deep-daze/blob/notebook/sleepy_daze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9LAaK_mcF-5"
      },
      "source": [
        "# sleepy-daze"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwGjJXqTb1yp"
      },
      "source": [
        "## 0. Install Dependencies - (Runtime > Restart Runtime after running this cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt0HIdhSgXJz",
        "cellView": "form"
      },
      "source": [
        "#@title Restart runtime after this finishes.\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "pytorch_version = \"1.7.1\" + \"+cu101\"\n",
        "torchvision_version = \"0.8.2\" +  \"+cu101\"\n",
        "\n",
        "!pip install torch=={pytorch_version} torchvision=={torchvision_version} -f https://download.pytorch.org/whl/torch_stable.html\n",
        "print(\"RESTART THE RUNTIME!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nedFKm_fbwOK"
      },
      "source": [
        "## 1. Define global variables (rerun as needed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjfGL0_X_2xr",
        "cellView": "form"
      },
      "source": [
        "text = 'The sirens of titan' # @param {type:\"string\"}\n",
        "image_width = \"512\" #@param [\"128\", \"256\", \"512\", \"\"]\n",
        "image_width = int(image_width)\n",
        "save_every = 1 # @param {type:\"integer\"}\n",
        "save_progress = True # @param {type:\"boolean\"}\n",
        "seed = 657345 # @param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPYDuuCFbmRa"
      },
      "source": [
        "## 2. Generate an image from text with big-sleep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7ziCWzZ735av",
        "cellView": "form"
      },
      "source": [
        "\n",
        "\n",
        "%mkdir /content/bs_temp\n",
        "%cd /content/bs_temp\n",
        "!pip install regex deep-daze big-sleep\n",
        "\n",
        "bs_learning_rate = 6e-2 # @param {type:\"number\"}\n",
        "bs_iterations = 500 # @param {type:\"integer\"}\n",
        "\n",
        "import big_sleep\n",
        "import torch\n",
        "\n",
        "imagine = None\n",
        "\n",
        "imagine = big_sleep.Imagine(\n",
        "    image_size=image_width,\n",
        "    text=text,\n",
        "    save_every=save_every,\n",
        "    lr=bs_learning_rate,\n",
        "    save_best=True,\n",
        "    iterations=bs_iterations,\n",
        "    epochs=1,\n",
        "    save_progress=save_progress,\n",
        "    seed=seed\n",
        ")\n",
        "imagine()\n",
        "del imagine\n",
        "imagine = None\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiLo1o31WE6S"
      },
      "source": [
        "# 3. Prime deep-daze with big-sleep's output. \n",
        "- big-sleep seems to leak some memory, so you may need to restart the runtime, and rerun [1]\n",
        "\n",
        "- Leave change_text empty to use global variable.\n",
        "- 26 layers is about as high as you can go in colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJD9wLP8-08K",
        "cellView": "form"
      },
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "%mkdir /content/dd_temp\n",
        "%cd /content/dd_temp\n",
        "\n",
        "import deep_daze\n",
        "start_image_path = text.replace(\" \", \"_\") + \".best.png\"\n",
        "!cp /content/bs_temp/{start_image_path} /content/dd_temp\n",
        "\n",
        "\n",
        "change_text = \"\" #@param {type: \"string\"}\n",
        "if change_text is not \"\":\n",
        "   text = change_text\n",
        "dd_num_layers = 26 # @param {type:\"integer\"}\n",
        "dd_learning_rate = 1e-5  # @param {type: \"number\"}\n",
        "dd_iterations = 500 # @param {type:\"integer\"}\n",
        "dd_epochs = 1  # @param {type:\"integer\"}\n",
        "initial_learning_rate = 2e-4  # @param {type:\"number\"}\n",
        "initial_iterations =  100# @param {type: \"integer\"}\n",
        "dd_batch_size = 8 # @param {type: \"integer\"}\n",
        "dd_gradient_accumulate_every = 1 # @param {type: \"integer\"}\n",
        "\n",
        "imagine = None # Clears the GPU memory hopefully...\n",
        "\n",
        "imagine = deep_daze.Imagine(\n",
        "    text,\n",
        "    lr=dd_learning_rate,\n",
        "    num_layers=dd_num_layers,\n",
        "    batch_size=dd_batch_size,\n",
        "    gradient_accumulate_every=dd_gradient_accumulate_every,\n",
        "    epochs=dd_epochs,\n",
        "    iterations=dd_iterations,\n",
        "    image_width=image_width,\n",
        "    save_every=save_every,\n",
        "    save_progress=save_progress,\n",
        "    seed=seed,\n",
        "    open_folder=False,\n",
        "    save_date_time=False,\n",
        "    start_image_path=start_image_path,\n",
        "    start_image_train_iters=initial_iterations,\n",
        "    theta_initial=30,\n",
        "    theta_hidden=30,\n",
        "    start_image_lr=initial_learning_rate,\n",
        ")\n",
        "imagine()\n",
        "\n",
        "del imagine\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlkD3f9ja_US"
      },
      "source": [
        "# 4. Create a video of the whole thing\n",
        "- filename **must end in .mp4**\n",
        "- higher crf for more compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwIZNCPZhSBT",
        "cellView": "form"
      },
      "source": [
        "fps = 30 #@param {type:\"integer\"}\r\n",
        "crf = 5 #@param {type:\"integer\"}\r\n",
        "filename = \"sleepy-daze.mp4\" #@param {type:\"string\"}\r\n",
        "text_with_underscores = text.replace(\" \", \"_\")\r\n",
        "%cd /content/bs_temp\r\n",
        "bs_ffmpeg_fmt_str = text_with_underscores + \".%d.png\"\r\n",
        "bs_output_video = text.replace(\" \", \"_\") + \".mp4\"\r\n",
        "!ffmpeg -r {fps} -i {bs_ffmpeg_fmt_str} -pix_fmt yuv420p -crf {crf} -y {bs_output_video}\r\n",
        "\r\n",
        "%cd /content/dd_temp\r\n",
        "dd_ffmpeg_fmt_str = text_with_underscores + \".%06d.png\"\r\n",
        "dd_output_video = text.replace(\" \", \"_\") + \".mp4\"\r\n",
        "!ffmpeg -r 30 -i {dd_ffmpeg_fmt_str} -pix_fmt yuv420p -crf {crf} -y {bs_output_video}\r\n",
        "%cd /content\r\n",
        "!echo file /content/bs_temp/{bs_output_video} > file_order.txt\r\n",
        "!echo file /content/dd_temp/{dd_output_video} >> file_order.txt\r\n",
        "!ffmpeg -f concat -safe 0 -i file_order.txt -c copy {filename}\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}